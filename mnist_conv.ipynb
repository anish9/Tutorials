{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn_work_tf2.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdfKFkd1fLXN",
        "colab_type": "code",
        "outputId": "f0e3a9fd-d4b3-4be2-83f2-e3b700cfdc0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import  MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "# drive.mount(\"gdrive\")\n",
        "# print(tf.__version__)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n",
            "Drive already mounted at gdrive; to attempt to forcibly remount, call drive.mount(\"gdrive\", force_remount=True).\n",
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpJWXdZXcgB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist().load_data()\n",
        "\n",
        "train_image = np.reshape(train_images,(-1,28,28,1))/255.\n",
        "train_label = tf.keras.utils.to_categorical(train_labels)\n",
        "data = tf.data.Dataset.from_tensor_slices((train_image,train_label)).shuffle(1024).batch(600)\n",
        "data_aug = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)])\n",
        "\n",
        "def cnn():\n",
        "  inp = Input(shape=(28,28,1))\n",
        "  aug = data_aug(inp)\n",
        "  cn0 = Conv2D(64,(3,3),activation=\"relu\")(aug)\n",
        "  cn0 = MaxPooling2D((2,2))(cn0)\n",
        "  bn0 = BatchNormalization(axis=-1)(cn0)\n",
        "  cn1 = Conv2D(128,(3,3),activation=\"relu\")(bn0)\n",
        "  cn1 = MaxPooling2D((2,2))(cn1)\n",
        "  bn1 = BatchNormalization(axis=-1)(cn1)\n",
        "\n",
        "  den = Flatten()(bn1)\n",
        "  den = Dense(10)(den)\n",
        "  den = Activation(\"softmax\")(den)\n",
        "\n",
        "  build = Model(inp,den)\n",
        "  return build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yADybf52ciwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mod = cnn()\n",
        "optim = tf.keras.optimizers.Nadam(1e-4)\n",
        "@tf.function\n",
        "def train_batch(x,y):\n",
        "  with tf.GradientTape() as t:\n",
        "    funcl = mod(x)\n",
        "    lossl = tf.keras.losses.categorical_crossentropy(y,funcl)\n",
        "    grad = t.gradient(lossl,mod.trainable_variables)\n",
        "    optim.apply_gradients(zip(grad,mod.trainable_variables))\n",
        "  return tf.reduce_mean(lossl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvjZU5JAcn2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start_train(epochs):\n",
        "  for _ in range(epochs):\n",
        "    for s,(xin,yout) in enumerate(data):\n",
        "      out = train_batch(xin,yout)\n",
        "      print(\"step %s | loss : %.2f\"%(s,out))\n",
        "\n",
        "# start_train(3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}